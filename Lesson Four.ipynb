{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistical Testing\n",
    "You did it! You made it to week four. We've saved one of the best (and hardest) lessons for last. This lesson will cover statistical testing within Jupyter Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "Let's go ahead and import the necessary packages. Again, we'll go ahead and import Numpy and Pandas. This time around, we'll also be importing **SciPy**. SciPy, short for Scientific Python is a package that allows us to use scientific and mathematic tools for working with data. It works extremely well with Pandas and NumPy since it was created by the same developers. Speficically, we'll be importing the **subpackage** stats from SciPy. All a subpackage is is a package within another package. We'll import the SciPy package, and you can try importing Pandas and Matplotlib yourself below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "\n",
    "# TODO: Import pandas (with the alias pd)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also import the random package, but you don't have to worry about this; it's simply so that we can demonstrate some things later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our Data\n",
    "For this lesson, we'll be working with two different scientific datasets. The first dataset contains daily temperatures recorded in Florida and Colorado. The second dataset contains the daily temperature and humidity  recorded in Florida only. This data comes from NEON, where all of the other data that you have worked with thus far comes from as well! Interestingly enough, the Florida data that we'll be working with today comes from the NEON DSNY site, which is located in Disney! Check out the links for more information on the [DSNY](https://www.neonscience.org/field-sites/field-sites-map/DSNY) site or the [CPER](https://www.neonscience.org/field-sites/field-sites-map/CPER) site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/temperatureData.csv', index_col=0)\n",
    "humidity_data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/humidityData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Tests\n",
    "**Mean Tests** allow us to test how different two groups of similar data are by looking at the mean of the data. In our case, we're dealing with similar data from two different locations: temperatures recorded at DSNY and temperatures recorded at CPER (in Celsius). Let's examine the first five values from our `temperature_data` dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine first five values in the temperature_data dataframe\n",
    "temperature_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have the date and time in one column, the DSNY site temperature (in degrees Celsius) in the second column, and the CPER site temperature (in degrees Celsius) in the last column. Say we wanted to determine whether the mean temperatures over the course of the year differed for the two sites. We could use a **T-test** to examine whether there is a **statistically significant** difference in the mean yearly temperatures for the two sites. Try examining the mean of the DSNY data, and the mean of the CPER data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean temperature at DSNY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean temperature at CPER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's try plotting a histogram for the temperatures of the two sites. We'll plot them on the same plot, and use `alpha=0.5` such that we can see the data on top of one another. Furthermore, we'll use `plt.legend()` to label which color corresponds to which dataset. After running the code below, try adding axis labels and a title to say what the data is showing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(temperature_data['TemperatureDSNY'], alpha=0.5)\n",
    "plt.hist(temperature_data['TemperatureCPER'], alpha=0.5)\n",
    "plt.legend(['DSNY', 'CPER'])\n",
    "\n",
    "# TODO: add a title and axis labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the temperatures recorded at CPER and DSNY are pretty different throughout 2019. Even though our plot gives us a reason to believe that there is a significant difference in the mean temperature between DSNY and CPER, we have to use a T-test to confirm this. We can achieve this using the `stats.ttest_ind` method to conduct and independent t-test on our two data columns. \n",
    "\n",
    "**NOTE** you may have noticed the `equal_var=False` argument set below. This has to do with the **variance** of our data. Though we won't go much into the variance represents, you can think of it as describing how spread out our data is. As we can see from the histogram above, our data is not equally spread out (CPER is wider than DSNY), and thus, our data does not have equal variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(temperature_data['TemperatureDSNY'], temperature_data['TemperatureCPER'], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got a p-value of 0. Well, not exactly; Python will always have some rounding error, especially for some very small numbers. Since there was a clear difference between the means of the two sites, the p-value is extremely small for our data. This means that we can **reject the null** hypothesis and say that the mean temperatures in Colorado at the CPER site and in Florida at the DSNY site are significantly different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of statistical testing that we'll cover today is the **Correlation Test**. This allows us to see how much of a relationship two data columns have. However, data can have many forms of correlation. The most typical correlationship that is tested for is a **Linear Relationship**. This simply tests whether there's a linear relationship between two columns of our dataset. For example, check out the plot of some random data that we created below. Don't worry about the code itself for now, just take a look at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x + random.random() for x in range(10)]\n",
    "Y = [y for y in range(10)]\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our data forms what appears to be a line. The line is also pointing upward, which suggests a **positive correlation** between the x and y data. A positive correlation means that when one variable increases, the other variable is expected to increase as well. We can view this by plotting a line over our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,10],[0,10])\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the points that we plotted fall very close to the line. Next, we'll check out what is called a **negative correlation**. A negative correlation means that when one variable increases, we expect the other variable to decrease. Again, don't worry as much about the code than the plot itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plot this data with a line through it, we can better see the negative relationship in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.plot([0,10], [10,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we'll cover when it comes to correlation is how correlated data is. In the two figures above, we could say that our data is **strongly linearly correlated**, which means that the data follows a very linear patter. However, if we had data such as below, we would say that our data has a **weak linear correlation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([10 * random.random() for x in range(10)] , Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our data barely has a pattern at all. Now that you have a good understanding about how correlation works, let's try checking out our own data. First, let's examine the last five values within our `humidity_data` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine the last five values within the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot temperatures versus humidity on a single chart\n",
    "plt.scatter(humidity_data['Temperature'], humidity_data['RelativeHumidity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we don't see must of a pattern with this data at all. The most apparent feature of this data is the **cluster** at the top right; this suggests that higher temps likely coencide with higher humidity values. We'll start with a **Pearson Correlation**, which simply measures whether or not there is a linear relationship between two data. A perfect, positive linear relationship would result in a **Correlation Coefficient** of 1, whereas a perfect negative linear relationship would result in a correlation coefficient of -1. Fortunately, Pandas already has a `corr()` method built in, so we don't even have to bother with using Scipy for this case. The code below will calculate the Pearson Correlation between the temperature and the relative humidity at DSNY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_data['Temperature'].corr(humidity_data['RelativeHumidity'], method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got a correlation coefficient of 0.0787. This is close to zero, which suggests that there is no linear correlation between our data. This is evident in our plot above, so no surprises here. Next, we'll try a **Spearman Correlation**, which simply measures how related two data points are. The benefit of using the Spearman Correlation is that the data doesn't have to be linear, all it has to have is some form of a relationship that follows a line or a curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_data['Temperature'].corr(humidity_data['RelativeHumidity'], method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, this correlation coefficient tells us that our data has a negative relationship; in other words, as the temperature goes up, the humidity tends to go down. However, our coefficient is once again very close to zero, and therefore very weak. Nonetheless, we do see that there is a trend in the upper right hand corner of our plot! This does suggest that our data has some form of a relationship present. We could try **Clustering**, but that's a whole different story in terms of computation. For now, we'll stick with mean and correlation tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, that's all! Thank you much for participating in this course. Now, it's time for you to dive deeper into your data. We gave you the tools you need to do so, so be sure to dig in and ask for help if needed. Good luck! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
