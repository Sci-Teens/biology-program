{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Processing\n",
    "Welcome back! We hope all is well, and that you're ready to dive back into processing your data! In this week's lesson, we'll cover some techniques for examining your dataset.\n",
    "\n",
    "As we go, be sure to ask plenty of questions, and never hesitate to let us know if we're moving too quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "Before we can get started with writing our notebook and diving into some data, we have to import some packages. Packages are essentially pre-built bundles of code that allow us to achieve common tasks that we wouldn't be able to achieve in plain Python. For starters, we'll be working with two of the most commonly used packages in Python Data Science: NumPy and Pandas. \n",
    "### NumPy\n",
    "Numpy, short for **Num**erical **Py**thon, is a package that provides us with tools for working with lists of numbers, or **Arrays**. \n",
    "### Pandas\n",
    "Pandas is a package that comes with many built in tools for examining and manipulating data. We'll use this package a lot throughout this course to help us understand and dig deeply into our data. <br>\n",
    "\n",
    "Without further ado, let's get started by importing both NumPy and Pandas. You'll notice that we're importing numpy \"as np\" and importing pandas \"as pd\". All this means is that we're choosing to rename the packages as we import them. This is only done because we're pretty lazy, and don't feel like typing out \"numpy\" or \"pandas\" every time we want to use the package; \"np\" and \"pd\" are much quicker to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data\n",
    "Typically, this is one of the trickiest steps in data science; data is typically a jumbled mess, and usually never comes bundled up in one convenient source. Luckily, we've pre-bundled the data so that it's easy to import and start working with. Our data is bundled up in a CSV, or **C**omma **S**eparated **V**alues file. All this means is that our data is divided into rows and columns by commas. For example, if we had a dataset that stored students' names and ages, the CSV file may look like:\n",
    "```\n",
    "Name,Age,\n",
    "Carlos,17,\n",
    "Sarah,16,\n",
    "```\n",
    "\n",
    "Feel free to take a look at the file itself if you'd like to see how this works. For now, though, we'll read in the data using pandas built-in read_csv method. A **Method** is essentially a function built into a package that allows us to achieve a specific task. In this case, our package is pandas, and our task is to read in our data from a CSV file. To do so, we'll use the ``read_csv()`` method. This method handles takes care of reading in the file for us so that we don't have to waste time getting our data into the Jupyter Notebook ourselves; I don't know about you, but I'd rather be exploring my data than figuring out how to read it in the first place!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = \"Ebola Virus Outbreak\" #@param [\"Wildfires and Bird Migration\", \"Yearly Carbon Fluctuations\", \"Ebola Virus Outbreak\"]\n",
    "lessons = {\n",
    "    \"Ebola Virus Outbreak\": \"https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/ebola.csv\",\n",
    "    \"Wildfires and Bird Migration\": \"https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/bird_counts_grsm.csv\"\n",
    "}\n",
    "\n",
    "dataset = lessons[variable_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in your data\n",
    "Let's go ahead and read in the dataset that you chose to work with. For starters, let's take a peek at the first five values within the dataset using the `head()` method. This method will always return the first five values from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, huh? Likewise, we can also use the ``tail()`` method to see the end of our data. This method will always return the last five values from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more method that we recommend you use when you first import data is the ``describe()`` method. This will allow you to explore some key information about your data. Let's check it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing data values\n",
    "Now that we're able to read in the data, let's see how we can access certain values from the dataset. You may have noticed by now that our dataset is arranged in rows and columns, similar to an Excel sheet. Pandas conveniently stores each of our columns so that they can be accessed by their name. Each column within a Pandas DataFrame is called a **Series**. For example, if our dataset included a column named *People*, we could access that column using ``data['People']``. Let's try it out: Choose one of the columns that you see from the ``data.head()`` or ``data.tail()`` cells, and access that column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Access a column from your data\n",
    "data['<COLUMN NAME>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Access another column\n",
    "data['<ANOTHER COLUMN NAME>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge! \n",
    "Here's a tricky one: What if we want to access multiple columns of data at a time? See if you can do this yourself below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Access two columns at once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps instead of getting a column from our data, we want to access a specific row. We can achieve this by using **iloc**. Here, we can pass in **integer** values representing which row we want to fetch. Here's the catch: Python is **zero-indexed**, which means, instead of starting counting from one, it starts counting from zero. This is a bit tricky to get used to at first, so make sure to practice this below. The code below gets the first row from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important tool at your disposal in Python, and Pandas, is **slicing** the data. This allows us to select multiple rows at once. For example, if we wanted to select rows three through five of the data, we would use the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have notices that although the slice starts at three, we tell it to end at six. Why not five, we only want rows three of five! Slicing works by including the first number specified, but excluding the last number specified. For example, ```iloc[10:20]``` fetches rows nine through nineteen, and ```iloc[7:10]``` selects rows six through nine. You're absolutely justified in being confused by this at first, but don't worry; with practice, this will become much easier to understand. Try out some more slicing techniques below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select rows two through ten\n",
    "data.iloc[  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select rows seven through fourteen\n",
    "data.iloc[  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "This one has a simple solution, though there's a super simple way to achieve it as well. We didn't teach this yet, so props to you if you can figure out the shorthand way to select the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: select all rows up to row ten\n",
    "data.iloc[  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select all rows after row ten\n",
    "data.iloc[  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Statistics from our Data\n",
    "Now that we're able to access columns from our data, let's try getting some key statistics. We can start with the **mean**, **median**, and **standard deviation**. If you're unfamiliar with these statistics, be sure to check out our article on these statistics **LINK ARTICLE** or check out this YouTube video **LINK VIDEO**. \n",
    "\n",
    "In order to get the mean, media, and standard deviation of different columns in our data, we must first identify columns that contain **quantitative** data. The easiest way to identify quantitative data is to look for columns with a bunch of numbers. For example, if we had a dataset that contained people's height and name, \n",
    "```\n",
    "Name,Height (inches),\n",
    "Carlos,70,\n",
    "Sarah,66,\n",
    "```\n",
    "Then our quantitative data would be the *Height* column. The *Name* column, on the other hand, is called **categorical** data. This just means that this data belongs in categories (yep, you can consider your name a category.) If you're having trouble understanding quantitative or categorical data, we recommend you check out **LINK VIDEO**\n",
    "\n",
    "For now, we'll calculate the mean, median, and standard deviation of a quantitative column within your data that you select. Go ahead and pick on out, and fill it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['<QUANTITATIVE COLUMN>'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['<QUANTITATIVE COLUMN>'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['<QUANTITATIVE COLUMN>'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook Quick Tip\n",
    "Wow, we've just started and it looks like we've already learned so much. In case you forget what any of the code does later, you can hover over a line of code in Google Colab to see what it does. Try it out above by hovering over ``.std()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice \n",
    "Great work today. For practice this week, we want you to get a taste of what's known as Exploratory Data Analysis (EDA). You can think of EDA as simply 'getting to know the data'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question One:** To start let's take a look at the first few lines of your dataset using the ``.head()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Two:** Do you notice any variables that are interesting? Which variables are quantitative (numerical) vs. qualitative (categorical)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Three:** Let's try accessing one of your columns in the dataset. If you need a refresher on how to do this, check out the 'Accessing Data Values' section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Four:** Now let's check out some of the rows of your dataset. Let's use ``.describe()`` to see how many rows are in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Five:** Let's grab rows 10-20 from your dataset. If you're not sure how to do this, try looking at the .iloc methods we looked at above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Six\":** Finally, let's sort your dataset by ascending values. We haven't taught you how to do this yet but take a look at the ``.sort_values()`` method. **Tip:** Think about what happens if you type `ascending = False` inside the parentheses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "Time for the challenge question! Get the median of the first and last 10 values of one of the columns in your dataset. This will involve ``.iloc`` and ``.mean()``. Set these two values to mean_first and mean_last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_first = \n",
    "#mean_last = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay that's all we have for this week. Please feel free to reach out to us through email or attend our weekly Office Hours for questions or help on the practice problems. If you want a great cheat sheet to remember what you learned today (and possibly learn more cool Pandas tricks,) be sure to check out https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
