{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistical Testing\n",
    "You did it! You made it to week four. We've saved one of the best (and hardest) lessons for last. This lesson will cover statistical testing within Jupyter Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "Let's go ahead and import the necessary packages. Again, we'll go ahead and import Numpy and Pandas. This time around, we'll also be importing **SciPy**. SciPy, short for Scientific Python is a package that allows us to use scientific and mathematic tools for working with data. It works extremely well with Pandas and NumPy since it was created by the same developers. Speficically, we'll be importing the **subpackage** stats from SciPy. All a subpackage is is a package within another package. We'll import the SciPy package, and you can try importing Pandas and Matplotlib yourself below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "\n",
    "# TODO: Import pandas (with the alias pd)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also import the random package, but you shouldn't worry about this much. It's used to generate random numbers that we can use as fake data for plotting later on. With this package, we can generate random numbers between zero and one using `random.random()`. You may notice below that we call `random.seed(1)`. This is so that whenever and wherever we run the code, the same random numbers are generated regardless. Be sure to check out [this video](https://www.khanacademy.org/computing/computer-science/cryptography/crypt/v/random-vs-pseudorandom-number-generators) if you'd like to learn more about what this package, and random number generators in general, do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our Data\n",
    "For this lesson, we'll be working with two different scientific datasets. The first dataset contains daily temperatures recorded in Florida and Colorado. The second dataset contains the daily temperature and humidity  recorded in Florida only. This data comes from NEON, where all of the other data that you have worked with thus far comes from as well! Interestingly enough, the Florida data that we'll be working with today comes from the NEON DSNY site, which is located in Disney! Check out the links for more information on the [DSNY](https://www.neonscience.org/field-sites/field-sites-map/DSNY) site or the [CPER](https://www.neonscience.org/field-sites/field-sites-map/CPER) site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/temperatureData.csv', index_col=0)\n",
    "humidity_data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/humidityData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Tests\n",
    "**Mean Tests** allow us to test how different two groups of similar data are by looking at the mean of the data. In our case, we're dealing with similar data from two different locations: temperatures recorded at DSNY and temperatures recorded at CPER (in Celsius). Let's examine the first five values from our `temperature_data` dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine first five values in the temperature_data dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have the date and time in one column, the DSNY site temperature (in degrees Celsius) in the second column, and the CPER site temperature (in degrees Celsius) in the last column. Say we wanted to determine whether the mean temperatures over the course of the year differed for the two sites. How would we go about doing so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we would need to determine, is whether or not our variation in data is due to random chance.The way statisticians quantify this variation is through **mean tests**. Mean tests measure whether or not the results we see are **statistically significant** or simply due to **chance error**. The way they do this is by measuring the probability of getting our results under the assumptions we have made with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better grasp of what I mean, let's take a look at a histogram. Remember that we can think of a histogram as representing the density of our data at certain values. As we can see in the graph, our data is centered around x-values of 26. This means the majority of our data is contained in a some x-values above and below our mean. We see that this is true as the bars are higher around the 26 but quickly fall off as we get further away from the mean. Now let's say, we get a value of 8 which we have shown on the graph. From our histogram, do you think this observation is significant?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Histogram](../images/histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our histogram, it looks like our observed value is very unlikely to occur due to random chance which would make it significant. Since there is almost no chance of us getting a value of 8 randomly, we can conclude that it has something to do with our experiment, i.e. something is causing our data to act this way. Besides simply looking at a graph, we could use a **T-test** to examine whether there is a **statistically significant** difference in the mean yearly temperatures for the two sites. T-tests take into account the mean and the variance of two variables to determine whether they are similar or different. Running a T-test gives us a **P-value** which is the probability that we got this value from random chance. For example, on our example histogram, the P-value of getting a x-value of 8 would be close to zero. As a rule of thumb, P-values less than 0.05 are significant as it means that more than 95% of the time, the value you see is not due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by examining the mean of the DSNY data, and the mean of the CPER data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean temperature at DSNY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean temperature at CPER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's try plotting a histogram for the temperatures of the two sites. We'll plot them on the same plot, and use `alpha=0.5` such that we can see the data on top of one another. Furthermore, we'll use `plt.legend()` to label which color corresponds to which dataset. After running the code below, try adding axis labels and a title to say what the data is showing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(temperature_data['TemperatureDSNY'], alpha=0.5)\n",
    "plt.hist(temperature_data['TemperatureCPER'], alpha=0.5)\n",
    "plt.legend(['DSNY', 'CPER'])\n",
    "\n",
    "# TODO: add a title and axis labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the temperatures recorded at CPER and DSNY are pretty different throughout 2019. Even though our plot gives us a reason to believe that there is a significant difference in the mean temperature between DSNY and CPER, we have to use a T-test to confirm this. We can achieve this using the `stats.ttest_ind` method to conduct and independent t-test on our two data columns. \n",
    "\n",
    "**NOTE** you may have noticed the `equal_var=False` argument set below. This has to do with the **variance** of our data. Though we won't go much into the variance represents, you can think of it as describing how spread out our data is. As we can see from the histogram above, our data is not equally spread out (CPER is wider than DSNY), and thus, our data does not have equal variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(temperature_data['TemperatureDSNY'], temperature_data['TemperatureCPER'], equal_var=False)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got a p-value of 0... <br>  \n",
    "Well, not exactly; there are limits to the size of numbers that we can store in Python, and there are also rounding errors. In this Jupyter notebook, the smallest number we can store is 0.000000000...... with about 300 more zeros before that. Therefore, it's likely that there was some form of rounding error in our calculation. Such is life; there are ways to avoid and overcome rounding errors, though that is a whole different discussion for another time. <br>  \n",
    "As we discussed earlier, extremely low p-value that we received means that we can say that the mean temperatures in Colorado at the CPER site and in Florida at the DSNY site have a difference in mean temperatures that is statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've looked at a couple different ways of visualizing our data. However, what if we want to be able to make predictions about our data? After all, there's no value in having thousands of data points of the past right? As scientists, programmers, and people, we want to be able to use the information we possess to learn more about the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of statistical testing that we'll cover today is the **Correlation Test**. This allows us to see how much of a relationship two data columns have. However, data can have many forms of correlation. The most typical correlationship that is tested for is a **Linear Relationship**. This simply tests whether there's a linear relationship between two columns of our dataset. For example, check out the plot of some random data that we created below. Don't worry about the code itself for now, just take a look at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x + random.random() for x in range(10)]\n",
    "Y = [y for y in range(10)]\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our data forms what appears to be a line. The line is also pointing upward, which suggests a **positive correlation** between the x and y data. A positive correlation means that when one variable increases, the other variable is expected to increase as well. We can view this by plotting the line \\$y = x\\$ over our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,10],[0,10])\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the points that we plotted fall very close to the line. Next, we'll check out what is called a **negative correlation**. A negative correlation means that when one variable increases, we expect the other variable to decrease. Again, don't worry as much about the code than the plot itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plot this data with the line \\$ y = -x + 10 \\$ through it, we can better see the negative relationship in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.plot([0,10], [10,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ways to compare different types of correlations. The most common on you will is the called the **Pearson Correlation Coefficient** which simply measures how strong of a linear relationship two variables have. Another way to think of this correlation coefficient as being related to the slope of the line of best fit.<br> A perfect, positive linear relationship would result in a **Correlation Coefficient** of 1, whereas a perfect negative linear relationship would result in a correlation coefficient of -1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R value](../images/r-value.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above, we can see that the first graph is very strongly linearly correlated and we would expect a correlation coefficient closer to 1. In the second graph, they are negatively correlated so correlation coefficient is going to be close to -1. Because the absolute value of our coefficients are close to 1, we could say that our data is **strongly linearly correlated**. This means a linear pattern describes our data well. However, if we had data such as below, we would say that our correlation coefficient is small and close to 0. Therefore, we would say that our data has a **weak linear correlation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x+10 * (random.random()-.5) for x in range(10)] , Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Correlation](../images/correlation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a good understanding about how correlation works, let's try checking out our own data. First, let's examine the last five values within our `humidity_data` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine the last five values within the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot temperatures versus humidity on a single chart\n",
    "plt.scatter(humidity_data['Temperature'], humidity_data['RelativeHumidity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we don't see must of a pattern with this data at all. The most apparent feature of this data is the **cluster** at the top right; this suggests that higher temps likely coencide with higher humidity values. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fortunately, Pandas already has a `corr()` method built in, so we don't even have to bother with using Scipy for this case. The code below will calculate the Pearson Correlation between the temperature and the relative humidity at DSNY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_data['Temperature'].corr(humidity_data['RelativeHumidity'], method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got a correlation coefficient of 0.0787. This is close to zero, which suggests that there is no linear correlation between our data. This is evident in our plot above, so no surprises here. Next, we'll try a **Spearman Correlation**, which simply measures how related two data points are. The benefit of using the Spearman Correlation is that the data doesn't have to be linear, all it has to have is some form of a relationship that follows a line or a curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_data['Temperature'].corr(humidity_data['RelativeHumidity'], method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, this correlation coefficient tells us that our data has a negative relationship; in other words, as the temperature goes up, the humidity tends to go down. However, our coefficient is once again very close to zero, and therefore very weak. Nonetheless, we do see that there is a trend in the upper right hand corner of our plot! This does suggest that our data has some form of a relationship present. For now, we'll stick with mean and correlation tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, that's all! Thank you much for participating in this course. We understand that this was a pretty intense four weeks but we hope that you've learned a lot about how to analyze and manipulate data. <br>Now, it's time for you to dive deeper into your own datasets. We gave you the tools you need to do so, so be sure to dig in and ask for help if needed. Good luck! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = \"Ebola Virus Outbreak\" #@param [\"Wildfires and Bird Migration\", \"Yearly Carbon Fluctuations\", \"Ebola Virus Outbreak\"]\n",
    "lessons = {\n",
    "    \"Ebola Virus Outbreak\": \"https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/ebola.csv\",\n",
    "    \"Wildfires and Bird Migration\": \"https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/bird_counts_grsm.csv\",\n",
    "    \"Mosquito Counts\": \"https://raw.githubusercontent.com/Sci-Teens/course-one/main/data/mosquito.csv\"\n",
    "}\n",
    "\n",
    "dataset = lessons[variable_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore your data!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
