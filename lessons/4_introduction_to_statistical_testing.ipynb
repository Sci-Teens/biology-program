{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistical Testing\n",
    "You did it! You made it to week four. We've saved one of the best (and hardest) lessons for last. This lesson will cover statistical testing within Jupyter Notebooks. <br>\n",
    "![statistics](https://media.giphy.com/media/wdiR7d9Cctec8/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📲 Section One: Importing Packages\n",
    "Let's go ahead and import the necessary packages. Again, we'll go ahead and import Numpy and Pandas. This time around, we'll also be importing **SciPy**. Speficically, we'll be importing the **subpackage** stats from SciPy. All a subpackage is is a package within another package. We'll import the SciPy package, and you can try importing Pandas and Matplotlib yourself below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy\n",
    "SciPy, short for Scientific Python is a package that allows us to use scientific and mathematic tools for working with data. It works extremely well with Pandas and NumPy since it was created by the same developers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "\n",
    "# TODO: Import pandas (with the alias pd)\n",
    "...\n",
    "\n",
    "# TODO: Import matplotlib's pyplot (with the alias plt)\n",
    "...\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block below ensures whenever and wherever we run the code, the same random numbers are generated regardless. Be sure to check out the video below if you'd like to learn more about what this package, and random number generators in general, do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "`<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/GtOt7EBNEwQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our Data\n",
    "For this lesson, we'll be working with two different scientific datasets. The first dataset contains Florida’s Covid Data whereas the second dataset contains the New York covid data. The purpose of this notebook is to start getting you to think on how you can make comparisons with datasets of different states to provide key insights! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/biology-program/main/data/florida_covid_data_the_atlantic.csv')\n",
    "new_york_data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/biology-program/main/data/new_york_covid_data_the_atlantic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Section Two: Mean Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine first five values in the New York dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine first five values in the Florida dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we would need to determine, is whether or not our variation in data is due to random chance.The way statisticians quantify this variation is through **mean tests**. Mean tests measure whether or not the results we see are **statistically significant** or simply due to **chance error**. The way they do this is by measuring the probability of getting our results under the assumptions we have made with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a Histogram to look at how our data is distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a histogram of the daily New York deaths. Include a title and \n",
    "# appropriate axes labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a histogram of the daily Florida deaths. Include a title and \n",
    "# appropriate axes labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a **T-test** to examine whether there is a **statistically significant** difference in the mean yearly temperatures for the two sites besides simply looking at a histogram. T-tests take into account the mean and the variance of two variables to determine whether they are similar or different. Running a T-test gives us a **P-value** which is the probability that we got this value from random chance.\n",
    "\n",
    "First, let's look at the mean deaths per day in Florida and New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean daily deaths in New York\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean daily deaths in New York\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the histograms and the means that we calculated, we can begin to believe that there is a significant difference between the distribution of daily COVID deaths in Florida and in New York. We can achieve this using the `stats.ttest_ind` method to conduct and independent t-test on our two data columns. \n",
    "\n",
    "**NOTE** you may have noticed the `equal_var=False` argument set below. This has to do with the **variance** of our data. Though we won't go much into the variance represents, you can think of it as describing how spread out our data is. As we can see from the histogram above, our data is not equally spread out (CPER is wider than DSNY), and thus, our data does not have equal variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(new_york_data['deathIncrease'], florida_data['deathIncrease'], equal_var=False)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this p-value, we can safetly assume that there is a significant difference between the mean number of daily COVID deaths in Florida and New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Section Three: Correlation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of statistical testing that we'll cover today is the **Correlation Test**. This allows us to see how much of a relationship two data columns have. However, data can have many forms of correlation. The most typical correlationship that is tested for is a **Linear Relationship**. Don't worry about the code itself for now, just take a look at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x + random.random() for x in range(10)]\n",
    "Y = [y for y in range(10)]\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our data forms what appears to be a line. The line is also pointing upward, which suggests a **positive correlation** between the x and y data. A positive correlation means that when one variable increases, the other variable is expected to increase as well. We can view this by plotting the line \\$y = x\\$ over our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,10],[0,10])\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the points that we plotted fall very close to the line. Next, we'll check out what is called a **negative correlation**. A negative correlation means that when one variable increases, we expect the other variable to decrease. Again, don't worry as much about the code than the plot itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plot this data with the line \\$ y = -x + 10 \\$ through it, we can better see the negative relationship in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.plot([0,10], [10,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ways to compare different types of correlations. The most common on you will is the called the **Pearson Correlation Coefficient** which simply measures how strong of a linear relationship two variables have. Another way to think of this correlation coefficient as being related to the slope of the line of best fit.<br> A perfect, positive linear relationship would result in a **Correlation Coefficient** of 1, whereas a perfect negative linear relationship would result in a correlation coefficient of -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above, we can see that the first graph is very strongly linearly correlated and we would expect a correlation coefficient closer to 1. In the second graph, they are negatively correlated so correlation coefficient is going to be close to -1. Because the absolute value of our coefficients are close to 1, we could say that our data is **strongly linearly correlated**. This means a linear pattern describes our data well. However, if we had data such as below, we would say that our correlation coefficient is small and close to 0. Therefore, we would say that our data has a **weak linear correlation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x+10 * (random.random()-.5) for x in range(10)] , Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if there's a correlation between the number of people currently hospitalized with COVID and the number of daily deaths caused by COVID. Right off the bat, we would assume that there would be some form of relationship between these data: more hospitalizations likely leads to more deaths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot increase in hospitalizations versus daily COVID deaths for New York. Include \n",
    "# a title and appropriate axes labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, Pandas already has a `corr()` method built in, so we don't even have to bother with using SciPy for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_data['deathIncrease'].corr(new_york_data['hospitalizedCurrently'], method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got a correlation coefficient of 0.93. This is close to one, which suggests that there is a very strong relationship between these data. This is evident in our plot above, so no surprises here. Next, we'll try a **Spearman Correlation**, which simply measures how related two data points are. The benefit of using the Spearman Correlation is that the data doesn't have to be linear, all it has to have is some form of a relationship that follows a line or a curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york_data['deathIncrease'].corr(new_york_data['hospitalizedCurrently'], method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get a stronger correlation value since our data doesn't have to be linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✏️ Practice\n",
    "That was our last and hardest lesson yet, so props for making it through the course! Let's go ahead and practice the skills and techniques we learned today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question One\n",
    "Let's determine if there's any correlation between the total number of people hospitalized, and the total number of people recovered in New York. This problem is three-fold: First, we'll create a scatterplot of our data to view the number of people hospitalized versus the number of people recovered for each date. Then, we'll go ahead and conduct both a Pearson and a Spearman Correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a scatterplot of recovered patients and hospitalized patients in New York\n",
    "# *Hint*: We want to see the cumulative hospitalizations, not the daily hospitalizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the Pearson correlation between recovered and hospitalized individuals \n",
    "# in New York\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the Spearman correlation between recovered and hospitalized individuals \n",
    "# in New York\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Two\n",
    "Let's see if the mean number of tests issued between Florida and New York differ. This problem is three-fold: First, we'll create a histogram of our data to view the distribution of tests issued each day. Then, we'll go ahead and compute a t-test to see how the distributions of these data compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram of the New York daily tests issued \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram of the Florida daily tests issued \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform a T-test to compare the mean values of tests issued in\n",
    "# each state. Ensure to compute an independent T-test, and assume that \n",
    "# these distributions don't have the same variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎 Exploration\n",
    "Now it's time to explore our data. We've provided the links to the New York and Florida data above, and below are the links to California and Georgia COVID data. \n",
    "- California: https://raw.githubusercontent.com/Sci-Teens/biology-program/main/data/california_covid_data_the_atlantic.csv\n",
    "- Georgia: https://raw.githubusercontent.com/Sci-Teens/biology-program/main/data/georgia_covid_data_the_atlantic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
