{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Jupyter Notebooks\n",
    "Welcome, and thanks for joining us for this course on working in Jupyter Notebook environments to process data. In this first lesson of our four-part series, we'll get you set up and running in a Jupyter Notebook environment. \n",
    "\n",
    "As we go, be sure to ask plenty of questions, and never hesitate to let us know if we're moving too quickly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "Before we can get started with writing our notebook and diving into some data, we have to import some packages. Packages are essentially pre-built bundles of code that allow us to achieve common tasks that we wouldn't be able to achieve in plain Python. For starters, we'll be working with two of the most commonly used packages in Python Data Science: NumPy and Pandas. \n",
    "### NumPy\n",
    "Numpy, short for **Num**erical **Py**thon, is a package that provides us with tools for working with lists of numbers, or **Arrays**. \n",
    "### Pandas\n",
    "Pandas is a package that comes with many built in tools for examining and manipulating data. We'll use this package a lot throughout this course to help us understand and dig deeply into our data. <br>\n",
    "\n",
    "Without further ado, let's get started by importing both NumPy and Pandas. You'll notice that we're importing numpy \"as np\" and importing pandas \"as pd\". All this means is that we're choosing to rename the packages as we import them. This is only done because we're pretty lazy, and don't feel like typing out \"numpy\" or \"pandas\" every time we want to use the package; \"np\" and \"pd\" are much quicker to type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data\n",
    "Typically, this is one of the trickiest steps in data science; data usually never comes clean, and usually never comes bundled up in one convenient source. Luckily, we've pre-bundled the data so that it's easy to import and start working with. Our data is bundled up in a CSV, or **C**omma **S**eparated **V**alues file. All this means is that our data is divided into rows and columns by commas. For example, if we had a dataset that stored students' names and ages, the CSV file may look like:\n",
    "```\n",
    "Name,Age,\n",
    "Carlos,17,\n",
    "Sarah,16,\n",
    "```\n",
    "\n",
    "Feel free to take a look at the file itself if you'd like to see how this works. For now, though, we'll read in the data using pandas built in read_csv method. A **Method** is essentially a function built into a package that allows us to achieve a specific task. In this case, our package is pandas, and our task is to read in our data from a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
